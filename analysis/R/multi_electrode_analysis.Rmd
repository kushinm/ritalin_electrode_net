---
title: "multielectrode analysis"
author: "Kushin Mukherjee"
output:
  html_document:
    df_print: paged
---

This is a notebook for analysis of the effects of Ritalin on the PFC and dmStriatum

The electrode reading CSV files are quite large so I recommend using fread over read.csv

```{r setup, include=FALSE, echo=FALSE}
require("knitr")
knitr::opts_knit$set(root.dir = normalizePath("../..")) 

```

Loading in required libraries

```{r include=FALSE, echo=FALSE}
library(tidyverse)
library(glmnet)
library(glmnetUtils)
library(data.table)
library(reshape2)
```

Functions for running cross validated lasso and ridge regressions with GLMnet:


This function trims empty entries or NAs from the electrode data

```{r}

trimNA<-function(x){
  #This function removes columns with an NA value from the matrix
  x <- as.matrix(x) #make sure it's a matrix
  s <- c(1:dim(x)[2])[!is.na(colSums(x))] #Vector of columns without NA values
  x[,s] #Return matrix with only those columns
}

```


Deprecated function. Don't delete for now
```{r}

T_CV<-function(x, y, pho = 0.1, a = 0, pflag = T){
  #x = data matrix
  #y = labels
  #pho = proportion of items to hold out
  #a = alpha (mixing proportion) for elastic net. 1 is lasso, 0 is ridge

  
  nipcl <- length(y)/2 #number of items per class
  x <- x[order(y),]    #Sort data to make classes contiguous
  y <- y[order(y)]     #Sort labels to make classes contiguous
  
  #below creates a "shuffled" vector used to select hold-outs with equal numbers
  #of items held out from each class
  s <- c(c(1:nipcl)[order(runif(nipcl))], c(1:nipcl)[order(runif(nipcl))])
  nfolds <- floor(1/pho) #Compute number of folds as 1/proportion of holdouts
  nhos <- pho * nipcl    #Number of held-out items per class
  o <- rep(NA, times = nfolds)  #Vector to hold output
  i1= 1
  for(i1 in c(1:nfolds)){
    tsmin <- (i1-1)*nhos + 1 #Minimum index for test-set in each fold
    tsmax <- i1*nhos         #Maximum index for test-set in each fold

    xtrn <- x[(s < tsmin) | (s > tsmax),] #Training set
    ytrn <- y[(s < tsmin) | (s > tsmax)]  #Training labels
    
    xtst <- x[(s >= tsmin) & (s <= tsmax),]  #Testing set
    ytst <- y[(s >= tsmin) & (s <= tsmax)]   #Testing labels
    
    #Fit the model
    m <- cv.glmnet(xtrn, ytrn, family="binomial", alpha = a, type.measure = "class")
    
    if(pflag) plot(m) #Plot error curve if plot flag is true
    
    p <- predict(m, xtst, s= 'lambda.min', type= 'class') #Generate predictions of best model for test set
    p <- as.numeric(p) #Convert to binary rep for comparison to true labels
    o[i1] <- sum(p==ytst)/length(ytst)  #compute and store proportion correct for test set
  }
 return(list(o,mean(o))) #return vector of hold-out accuracy for each fold 

}



```


Main function for calculating cross validated accuracy of our models.
For each round of cross-validation we sample 3 trials out of 30 for both drug and no-drug condition which we hold out.
We then fit a elasticnet model to the rest of the trials using GLMnet (https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html)

We then get a measure of performance using this model to predict the drug condition for the 6 (3 drug, 3 non-drug) held out trials. We get an accuracy score for the model given by = number of trials correctly predicted/6
We repeat this process 10 times, giving us 10 accuracy scores, which we take the mean of to get a cross-validated accuracy score.
```{r}
calc_cv_acc<-function(full_x, full_y, a=0){  ## full_x is a matrix of electrode data for a single rat, y is the condition (drug or no-drug), a is the alpha parameter which modulates what weights we put on the lasso and ridge term. a = 0 is pure ridge regression and a = 1 is pure lasso.
  
running_acc_dc ={}
base_pool = c(1:30)
drug_pool = c(31:60)
for (i in 0:9) {
  
  base_sample = sample(base_pool,3) 
  base_pool = base_pool[!(base_pool%in%base_sample)]
  drug_sample = sample(drug_pool,3)
  drug_pool = drug_pool[!(drug_pool%in%drug_sample)]
  test_set = c(base_sample,drug_sample)
  fit_x = full_x[-(test_set),]
  test_x = full_x[test_set,]
  
  fit_y = full_y[-test_set]
  test_y =full_y[test_set]
  
  
  data_cols = as.matrix(fit_x)
  test_cols = as.matrix(test_x)

  model_dc <- cv.glmnet(data_cols,fit_y,family = "binomial",type.measure = "class", alpha = a)
  plot(model_dc)
  #model_dir <- cv.glmnet(data_cols,fit_dir, family = "binomial")
  
  pred_dc = as.numeric(predict(model_dc,test_cols, s = "lambda.min", type= 'class'))
  #pred_dir = as.numeric(predict.cv.glmnet(model_dir,test_cols,s = "lambda.min",type= 'class'))
  
  dc_acc= sum(pred_dc==test_y)/length(test_y)
  #dir_acc = 1 - (sum(abs(as.numeric(test_dir)-pred_dir))/length(pred_dir))
  
  running_acc_dc= append(running_acc_dc, dc_acc)
  #running_acc_dir= append(running_acc_dir, dir_acc)
  #plot(model_dg)
}
mean_acc = mean(running_acc_dc)
mean_acc
return(list(mean_acc, running_acc_dc))
}

```




```{r}
### Set some values for variables whose values we already know

num_rats_saline<-11
num_rats_mph<-8
num_electrodes<- fread('data/num_electrodes.csv')

```


Function to read in data and pass data to the cross-validation functions above
```{r}
### compute results for all rats of a particular kind (saline or mph)

agg_results<-function(num_rats, drug_type){ ## num_rats is the number of rats in that condition, drug_type is either 'saline' or 'mph'
all_results={}

for (this_rat in 1:num_rats){
base<-fread(paste0("data/rat",this_rat,drug_type,"_base.csv"))
drug<-fread(paste0("data/rat",this_rat,drug_type,"_drug.csv"))
full_x<- trimNA(rbind(base,drug))
full_y<-c(rep(0,30),rep(1,30))
this_data <- calc_cv_acc(full_x = full_x, full_y = full_y) ## mean accuracy plus individual cv accuracies for a single rat
all_results<-append(all_results, this_data) ## appending all data
}
return(all_results)
}
```


Now to run all the above functions

```{r}

results_list<- agg_results() ### insert two arguments in this function, the number of rats in the condition: either num_rats_mph or num_rats_saline and drug type: either 'mph' or 'saline' 
```


Plotting the accuracies for each rat. Each rat is on the x-axis and the y-axis represents the cross-validated classification accuracy for drug condition with each cross-validation fold as a black dot and the mean accuracy as a red dot
```{r}
results_list<- (all_results[seq(2,length(all_results),2)])
l={}
for (this_rat in 1:num_rats_saline){
  c = results_list[[this_rat]]
  l=rbind(l,c)
  
  
}
#all_results
l = cbind(l,seq(1,8))
results_df<- data.frame(l)

results_df
colnames(results_df)<- c('CV1','CV2','CV3','CV4','CV5','CV6','CV7','CV8','CV9','CV10','rat')
results_df<-results_df %>% rowwise() %>% mutate(Mean = mean(c(CV1,CV2,CV3,CV4,CV5,CV6,CV7,CV8,CV9,CV10)))
results_df




d <- melt(results_df, id.vars="rat")

# Everything on the same plot
ggplot(d, aes(rat,value)) + 
  geom_jitter(width = 0.2) + geom_point(results_df,mapping= aes(x=rat,y=Mean), col='red')+
  ggtitle("Set plot title here")+
  labs(x= "accuracy")

```

